{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "\n",
    "\n",
    "from category_encoders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackingClassifier: train:0.87011, test:0.86631\n",
    "## MajorityVotingClassifier: train: 0.86974, test:0.85974"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Projects/Assignment/PCode\n"
     ]
    }
   ],
   "source": [
    "#Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData = \"../PData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "f_name = dirPData + \"01_df_250k.pickle\"\n",
    "\n",
    "with (open(f_name,\"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_train = dict_['df_train']\n",
    "df_test = dict_['df_test']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the variables information\n",
    "f_name = dirPData + '01_vars.pickle'\n",
    "with open(f_name,\"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "vars_ind_numeric = dict_['vars_ind_numeric']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_ind_hccv = dict_['vars_ind_hccv']\n",
    "vars_notToUse = dict_['vars_notToUse']\n",
    "var_dep = dict_['var_dep']\n",
    "\n",
    "del f_name, dict_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace -99 with NaN\n",
    "df_train = df_train.replace(-99, np.NaN)\n",
    "df_test = df_test.replace(-99, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop columns we identified in Part A which had very high amount of null values\n",
    "vars_to_drop = ['a04', 'b06', 'd01' ,'d02', 'd03']\n",
    "vars_ind_numeric = [var for var in vars_ind_numeric if var not in vars_to_drop]\n",
    "vars_ind_categorical = [var for var in vars_ind_categorical if var not in vars_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = vars_to_drop)\n",
    "df_test = df_test.drop(columns = vars_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN with the mean of each column\n",
    "for var in vars_ind_numeric:\n",
    "    df_train[var] = df_train[var].fillna(df_train[var].mean())\n",
    "    df_test[var] = df_test[var].fillna(df_train[var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Target Encoding\n",
    "enc = TargetEncoder(cols=vars_ind_categorical)\n",
    "enc.fit_transform(df_train, df_train['target'])\n",
    "df_train_encoded = enc.transform(df_train, df_train['target'])\n",
    "df_test['target'] = np.NaN\n",
    "df_test_encoded = enc.transform(df_test)\n",
    "df_test.drop(columns = ['target'], inplace = True)\n",
    "df_test_encoded.drop(columns = ['target'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_encoded\n",
    "df_test = df_test_encoded\n",
    "del df_train_encoded, df_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 92)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split to train_test split\n",
    "X = df_train.drop(columns=['target']).values #need to drop the dep variable\n",
    "y = df_train['target'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175000, 91)\n",
      "(175000,)\n",
      "(75000, 91)\n",
      "(75000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 100, 1000], 'fit_intercept': [True],\n",
       "                         'l1_ratio': [0.25, 0.5, 0.75],\n",
       "                         'penalty': ['elasticnet'], 'solver': ['saga']},\n",
       "             refit=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'C':[0.1, 100, 1000],\n",
    "    'l1_ratio':[0.25, 0.5, 0.75],\n",
    "    'penalty':['elasticnet'],\n",
    "    'fit_intercept':[True],\n",
    "    'solver':['saga'] #saga solver support elastic net penalty\n",
    "    }\n",
    "#passing the scoring function in the GridSearchCV\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(), parameters,scoring='roc_auc',verbose =2, refit=False,cv=3, n_jobs=-1)\n",
    "lr_grid_search.fit(X_train, y_train) #fit on our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.25,\n",
       " 'penalty': 'elasticnet',\n",
       " 'solver': 'saga'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, l1_ratio=0.25, penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100, fit_intercept=True, l1_ratio=0.25, penalty='elasticnet', solver='saga')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  5.1min remaining: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 30, 50, 80],\n",
       "                         'max_features': ['sqrt'], 'n_estimators': [200]},\n",
       "             refit=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[200],\n",
    "    'max_depth':[10, 30, 50, 80],\n",
    "    'max_features':['sqrt']\n",
    "    }\n",
    "#passing the scoring function in the GridSearchCV\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), parameters,scoring='roc_auc',verbose =2, refit=False,cv=3, n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'max_features': 'sqrt', 'n_estimators': 200}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=30, max_features='sqrt', n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "('rf', RandomForestClassifier(n_estimators=200, max_depth=30, max_features='sqrt', random_state=42)),\n",
    "('logreg', LogisticRegression(C=100, fit_intercept=True, l1_ratio=0.25, penalty='elasticnet', solver='saga'))\n",
    "]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf',\n",
       "                                RandomForestClassifier(max_depth=30,\n",
       "                                                       max_features='sqrt',\n",
       "                                                       n_estimators=200,\n",
       "                                                       random_state=42)),\n",
       "                               ('logreg',\n",
       "                                LogisticRegression(C=100, l1_ratio=0.25,\n",
       "                                                   penalty='elasticnet',\n",
       "                                                   solver='saga'))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_clf.score(X_test, y_test) #calculate accuracy, dataset is balanced so accuracy is adequate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_pred = stacking_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2320945 , 0.64545593, 0.06937698, ..., 0.06108798, 0.33173128,\n",
       "       0.94071755])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701136661630816\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, stacking_pred)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pred_stacking = stacking_clf.predict_proba(df_test.values)[:,1]\n",
    "df_sub_partb = pd.DataFrame({\n",
    "    \"unique_id\": df_test[\"unique_id\"],\n",
    "    \"Predicted\": kaggle_pred_stacking\n",
    "})\n",
    "df_sub_partb.to_csv('../POutput/pd_sub_partc.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=100, l1_ratio=0.25,\n",
       "                                                 penalty='elasticnet',\n",
       "                                                 solver='saga')),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     max_features='sqrt',\n",
       "                                                     n_estimators=200))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting = VotingClassifier(estimators=[('lr', logreg), ('rf', rf)], voting='soft')\n",
    "voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7844666666666666"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_pred = voting.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37923258, 0.5762548 , 0.27444432, ..., 0.26459112, 0.40976281,\n",
       "       0.69307206])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697356784713044\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, voting_pred)\n",
    "print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pred_voting = voting.predict_proba(df_test.values)[:,1]\n",
    "df_sub_partc_voting = pd.DataFrame({\n",
    "    \"unique_id\": df_test[\"unique_id\"],\n",
    "    \"Predicted\": kaggle_pred_voting\n",
    "})\n",
    "df_sub_partc_voting.to_csv('../POutput/pd_sub_partc_voting.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
