{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNQvOgFJPwMR"
   },
   "source": [
    "# Final assignment: Part 1\n",
    "\n",
    "Part 1: The only type of model you should use for this part, is the H2OGeneralizedLinearEstimator model. You should:\n",
    "\n",
    "1. Deal appropriately with missings (for all numeric variables, -99 means missing).\n",
    "2. Deal with numerics - i.e. for at least some try linear splines (or another method of your choice to deal with non-linear effects)\n",
    "3. Deal with hccvs (eg using the feature encoding library that we looked at in lecture) (You do not need to deal with low cardinality categorical features since H2O will one-hot them for you.)\n",
    "4. Try out some interactions\n",
    "5. Try out some other features (eg division of numerics).\n",
    "\n",
    "Presumably you will train various models, submit your predictions on Kaggle and note the public leaderboard score.\n",
    "\n",
    "- Choose your best model, and for it: Create a function which carries out any data preparation and fitting:\n",
    "• The name of your function must be fn logistic\n",
    "• You must save your function in a (plain text) file with exactly the following\n",
    "name\n",
    "      en_<studentnumber>.py\n",
    "For example, if your student number is 123456789 then your function must be stored as en 123456789.py\n",
    "• The only input for your function should be the df train and df test datasets created in 01a ReadData. You may choose the smaller or larger train data, as you wish, but the score in your return statement should be consistent. Any data manipulation should be done by code in your function.\n",
    "• The only output from your function should be three items - in this order: – Your trained H2OGeneralizedLinearEstimator object\n",
    "– The test data, the data that you feed your object when you make predictions.\n",
    "– Your Kaggle public leaderboard score for this model, hardcoded as a number to 3 d.p.\n",
    "• Your function should be totally self contained. If it requires any import eg of numpy or pandas or from sklearn, you should do those imports in your function.\n",
    "3\n",
    "    \n",
    "• There should be no code at all in your .py file before the def statement and no code after the end of the return statement.\n",
    "• The code in your function should tidy (especially if you download if from a ipynb) and it should be well commented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDp4OfVkp5Ec"
   },
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Jnfy7xrPwMT"
   },
   "outputs": [],
   "source": [
    "### Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "#category encoders\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "#needed for fn_computeRatiosOfNumerics()\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1562674400140,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "lJ98I6jPPwMY",
    "outputId": "cb69b446-ac40-42c5-fdc9-29d67fc42c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Projects/final_assignment/PCode\n"
     ]
    }
   ],
   "source": [
    "#### Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../PData/'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "def fn_MAE(actuals, predictions):\n",
    "    return np.round(np.mean(np.abs(predictions - actuals)))\n",
    "\n",
    "def fn_RMSE(actuals, predictions):\n",
    "    return np.round(np.sqrt(np.mean((predictions - actuals)**2)))\n",
    "\n",
    "def fn_tosplines(x):\n",
    "    x = x.values\n",
    "    # hack: remove zeros to avoid issues where lots of values are zero\n",
    "    x_nonzero = x[x != 0]\n",
    "    ptiles = np.percentile(x_nonzero, [10, 20, 40, 60, 80, 90])\n",
    "    ptiles = np.unique(ptiles)\n",
    "    print(var, ptiles)\n",
    "    df_ptiles = pd.DataFrame({var: x})\n",
    "    for idx, ptile in enumerate(ptiles):\n",
    "        df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "    return(df_ptiles)\n",
    "\n",
    "def fn_computeRatiosOfNumerics(df, variables):\n",
    "## Process:\n",
    "# 1. Gets passed most important numeric variables\n",
    "# 2. Computes all pairwise ratios between each of these i.e\n",
    "# - get all permutations of length 2, and divide term 1 by term 2\n",
    "# e. Returns a dataframe containing engineered variables, with appropriately named columns\n",
    "\n",
    "#     variables = ['A','B','C'] #debugging\n",
    "    pairs = []\n",
    "    lst_series = []\n",
    "    for i in range(len(variables)+1):\n",
    "        for subset in permutations(variables, i):\n",
    "            if len(subset)==2: pairs.extend([subset])\n",
    "    temp_colnames = []\n",
    "    for elem in pairs:\n",
    "        ## create column names\n",
    "        temp_colname = 'ratio_{}.{}'.format(elem[0],elem[1])\n",
    "        temp_colnames.append(temp_colname)\n",
    "        #compute ratio\n",
    "        try: \n",
    "            srs_pair_ratio = df[elem[0]]/df[elem[1]]\n",
    "        except ZeroDivisionError:  \n",
    "            #if denominator is 0, will catch error and assign nan value to that ratio\n",
    "            srs_pair_ratio = np.nan\n",
    "            srs_pair_ratio = np.nan\n",
    "        srs_pair_ratio.rename(temp_colname, inplace=True)\n",
    "        lst_series.append(srs_pair_ratio)\n",
    "    #create dataframe with appropriate column names\n",
    "    df_2 = pd.DataFrame(index = df.index, columns = temp_colnames)\n",
    "    #fill dataframe with series\n",
    "    for idx, col in enumerate(df_2):\n",
    "        df_2[col] = lst_series[idx]\n",
    "    \n",
    "    \n",
    "    # Seems df division already catches ZeroDivisonError and assigns infinity value when denom = 0 but not numerator \n",
    "    # In such case, want 0 coefficient.\n",
    "    # Also want 0 coefficients when both numerator and denom are 0\n",
    "    # therefore replace all inf and nan values with zeroes\n",
    "    df_2.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3jUBL1RPwMf"
   },
   "outputs": [],
   "source": [
    "#### Load data via pickle\n",
    "f_name = dirPData + '01_df_250k.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_train = dict_['df_train']\n",
    "df_test  = dict_['df_test']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXQzUcqqPwMj"
   },
   "outputs": [],
   "source": [
    "f_name = dirPData + '01_vars.pickle'\n",
    "\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "vars_ind_numeric     = dict_['vars_ind_numeric']\n",
    "vars_ind_hccv        = dict_['vars_ind_hccv']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_notToUse        = dict_['vars_notToUse']\n",
    "var_dep              = dict_['var_dep']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'unique_id']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add 'unique_id' to vars_notToUse, remove it from list of numeric variables\n",
    "if 'unique_id' not in vars_notToUse:\n",
    "    vars_notToUse.extend(['unique_id']) ### weirdly, 'id' doesn't appear in index. I believe should use 'unique_id' instead but will leave both in for now.\n",
    "vars_ind_numeric = [var for var in vars_ind_numeric if var not in vars_notToUse]\n",
    "# vars_ind_numeric\n",
    "vars_notToUse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set index for train, val, design, test data\n",
    "#### Create folds to seperate train data into train, val, design, test\n",
    "rng = np.random.RandomState(2020)\n",
    "fold = rng.randint(0, 10, df_train.shape[0])\n",
    "df_train['fold'] = fold\n",
    "\n",
    "#get indices for each subset\n",
    "# idx_train  = df_train['fold'].isin(range(6))\n",
    "# idx_val    = df_train['fold'].isin([6, 7])\n",
    "# idx_design = df_train['fold'].isin(range(8))\n",
    "# idx_test = df_train['fold'].isin([8,9])\n",
    "idx_train  = df_train['fold'].isin(range(8))\n",
    "idx_val    = df_train['fold'].isin([7, 8])\n",
    "idx_design = df_train['fold'].isin(range(9))\n",
    "\n",
    "#drop fold column\n",
    "df_train.drop(columns='fold', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296690, 96)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n",
    "df_test.shape\n",
    "# df_train['fold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal with missings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 97)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#### IDENTIFY NULLS, MISSINGS\n",
    "print(df_train.shape)\n",
    "#collapse axis = 0 i.e. sum missing values,\n",
    "#store as series\n",
    "## Check for nulls\n",
    "srs_null = df_train.isnull().sum(axis=0) \n",
    "print(srs_null[srs_null>0]) #show which features have null values\n",
    "\n",
    "## Check for missings numerics which have been replaced with -99 (placeholder, really it is missing)\n",
    "#get percentage of missing values for each feature\n",
    "srs_missing = pd.DataFrame(df_train.loc[:,:]==-99).sum(axis=0)/len(df_train)\n",
    "# print(srs_missing[srs_missing!=0])\n",
    "\n",
    "#get list of variables which have more than x% missing values\n",
    "#arbitrarily setting threshold to 50% but could tune this parameter if time permits\n",
    "many_missings = [var for var in df_train.columns.values if srs_missing[var]>=.5 ]  \n",
    "\n",
    "## DO NOT USE VARIABLES WITH MORE THAN x% MISSINGS\n",
    "#add vars from many_missings to vars_notToUse, remove them from list of numeric variables\n",
    "vars_notToUse.extend(many_missings)\n",
    "#turn into set and set back into list - deals with issue of duplicates when running code multiple time\n",
    "vars_notToUse = list(set(vars_notToUse)) \n",
    "\n",
    "#remove variables in many_missings from var_ind_numeric\n",
    "vars_ind_numeric = [var for var in vars_ind_numeric if var not in vars_notToUse]\n",
    "# print([var for var in vars_ind_numeric if var in vars_notToUse])  #double check they've been removed: printed list should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MEAN-IMPUTE MISSINGS\n",
    "# list of variables to impute\n",
    "vars_toImpute = [var for var in srs_missing[srs_missing>0].index.tolist() if var not in many_missings]\n",
    "\n",
    "#get subset dataframe (only cols which are in variables_toImpute)\n",
    "#get only values != -99 -> this will mean that the missings will be returned as NaN. Can then use fillna\n",
    "df_temp=df_train[vars_toImpute][df_train[vars_toImpute]!=-99].copy()  #make a working copy\n",
    "\n",
    "#use fillna: computing the mean of each column and filling NaNs with this mean value.\n",
    "df_temp.fillna(df_temp.mean(), inplace=True)\n",
    "\n",
    "df_train[vars_toImpute] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 97)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare basis functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a04 [ 18.          36.          81.08778636  84.         180.        ]\n",
      "a15 [1. 2. 3. 4. 5. 6.]\n",
      "b01 [ 9. 26. 46. 54. 77. 87.]\n",
      "b05 [ 9. 10. 13. 14. 17. 19.]\n",
      "c01 [11. 21. 54. 88.]\n",
      "c03 [1. 2. 4. 5.]\n",
      "d01 [1.       3.       4.810065 5.       9.      ]\n",
      "d02 [1.         1.35343073 2.        ]\n",
      "d03 [1.         1.80588394 2.        ]\n",
      "e02 [11. 20. 41. 60. 80. 90.]\n",
      "e04 [12. 18. 39. 60. 81. 89.]\n",
      "e05 [ 9. 19. 39. 59. 79. 89.]\n",
      "e06 [20. 61. 76. 89.]\n",
      "e08 [16. 40. 61. 81. 90.]\n",
      "e09 [18. 43. 62. 79. 90.]\n",
      "e12 [11. 20. 41. 59. 79. 89.]\n",
      "e15 [13. 22. 36. 59. 83. 90.]\n",
      "f01 [13. 41. 59. 75.]\n",
      "f02 [10. 19. 40. 58. 79. 90.]\n",
      "f06 [ 9. 19. 60.]\n",
      "f11 [ 4.  6.  9. 11. 13. 15.]\n",
      "f13 [ 4.  6.  8.  9. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "### Spline numeric variables with cardinality higher than 8\n",
    "# define variables to spline\n",
    "vars_ind_tospline = df_train[vars_ind_numeric].columns[(df_train[vars_ind_numeric].nunique() > 8)].tolist()\n",
    "#Find the percentiles on train data only, then apply same percentiles to both train and test data, even if test data distribution is very different.\n",
    "#update df_train, df_test\n",
    "for var in vars_ind_tospline:\n",
    "    df_ptiles = fn_tosplines(df_train[var])\n",
    "    df_train.drop(columns=[var], inplace=True)\n",
    "    df_test.drop(columns=[var], inplace=True)\n",
    "    vars_ind_numeric.remove(var)\n",
    "    df_train = pd.concat([df_train, df_ptiles], axis=1, sort=False)\n",
    "    df_test = pd.concat([df_test, df_ptiles], axis=1, sort=False)\n",
    "    vars_ind_numeric.extend(df_ptiles.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 208)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296690, 207)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for convenience store dependent variable as y\n",
    "y = df_train[var_dep].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape\n",
    "# df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HCCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "21244\n",
      "e17       82\n",
      "e18      684\n",
      "e19    21244\n",
      "f10     1704\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### If want to use some cardinality threshold other than 30, can edit threshold below:\n",
    "th_card = 30\n",
    "srs_card = df_train[vars_ind_categorical].nunique()\n",
    "# srs_card = df_train_1m[cols_notNumeric].nunique()\n",
    "print(srs_card.min())\n",
    "print(srs_card.max())\n",
    "print(srs_card[srs_card>th_card])\n",
    "vars_ind_hccv = srs_card[srs_card>th_card].index.values.tolist()  #stores names of categorical variables with cardinality higher than threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HCCV encoding using category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LeaveOneOutEncoder(cols=vars_ind_hccv, sigma=0.3)\n",
    "enc.fit(df_train[idx_design], y[idx_design])\n",
    "df_train = enc.transform(df_train)  #encode hccvs in train data\n",
    "# df_train[vars_ind_hccv].head()\n",
    "\n",
    "df_test['target'] = np.nan  #add NaN target column to test dataset in order for it to have same shape as df_train\n",
    "df_test = enc.transform(df_test)  #encode hccvs in test data\n",
    "df_test.drop(columns='target', inplace=True)  #drop target column from df_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[vars_ind_hccv]  #see newly added hccv columns in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define features to be used\n",
    "features = vars_ind_numeric+vars_ind_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try out some interactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## TODO #############\n",
    "\n",
    "### Inspect coefficients from basic model with no interactions\n",
    "#load basic model\n",
    "# glm_basic_path=dirPData + 'GLM_model_python_1594684701152_8'\n",
    "glm_basic_path='/home/jovyan/Projects/final_assignment/PCode/../PData/GLM_model_python_1594684701152_8'\n",
    "glm_basic = h2o.load_model(path = glm_basic_path)  # load the model\n",
    "#plot\n",
    "glm_basic.std_coef_plot(num_of_features=10)\n",
    "#get list of 5 most important variables\n",
    "# vars_mostImp = [var[0].split('.')[0] for var in glm_basic.varimp()[0:5]]\n",
    "#note that glm_basic.varim() is made up of some onehots created by H2o on the fly when building the model, and thus some aren't actually present in the train/test frames\n",
    "#therefore can't refer to them before running a model, and we need to refer to the original variables before h2o onehots them\n",
    "# we extract these by:\n",
    "# - getting only the name of the variable\n",
    "# - splitting on onehot delimiter '.' and keeping only first part of result. This is name of original variable\n",
    "vars_mostImp = [var[0].split('.')[0] for var in glm_basic.varimp()[0:5]]\n",
    "#vars_mostImp = [var.split('.')[0] for var in vars_mostImp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maually add interaction columns to both TRAIN and TEST datasets (need exact same columns across both datasets)\n",
    "# df_enum.interaction(['A', 'B'], pairwise=False, max_factors=100, min_occurrence=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- df_all.any_factor\n",
    "- is.factor() and as.factor()\n",
    "- df_all[colname].levels()\n",
    "- df_all.interaction(['col1','col2'], args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try out some other features e.g. division of numerics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TODO #############\n",
    "#define THREE most important numeric variables\n",
    "glm_basic = h2o.load_model(path = glm_basic_path)  # load the basic model\n",
    "# plot largest standardised coefficients\n",
    "# glm_basic.std_coef_plot(num_of_features=10)\n",
    "# Get list of THREE most important variables\n",
    "vars_mostImp_numeric=[]\n",
    "for var in glm_basic.varimp():\n",
    "    orig_var = var[0].split('.')[0]\n",
    "    if orig_var in vars_ind_numeric:  #check if numeric\n",
    "        #add to list of important numeric vars\n",
    "        vars_mostImp_numeric.append(orig_var)\n",
    "    if len(vars_mostImp_numeric)>= 3:\n",
    "        break\n",
    "\n",
    "### COMPUTE RATIO COLUMNS FOR BOTH DATASETS\n",
    "df_temp_train = fn_computeRatiosOfNumerics(df_train, vars_mostImp_numeric)\n",
    "df_temp_test = fn_computeRatiosOfNumerics(df_test, vars_mostImp_numeric)\n",
    "\n",
    "#append new columns to df_train and df_test\n",
    "df_train[df_temp_train.columns.values] = df_temp_train\n",
    "df_test[df_temp_test.columns.values] = df_temp_test\n",
    "\n",
    "#\n",
    "vars_ind_numeric.extend(df_temp_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[vars_mostImp_numeric]\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COMPUTE RATIO COLUMNS FOR BOTH DATASETS\n",
    "# df_temp_train = fn_computeRatiosOfNumerics(df_train, vars_mostImp_numeric)\n",
    "# df_temp_test = fn_computeRatiosOfNumerics(df_train, vars_mostImp_numeric)\n",
    "\n",
    "# #append new columns to df_train and df_test\n",
    "# df_train[df_temp_train.columns.values] = df_temp_train\n",
    "# df_test[df_temp_test.columns.values] = df_temp_test\n",
    "\n",
    "# # df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp2[0][0]\n",
    "# temp_colnames = []\n",
    "# #compute ratios between columns\n",
    "# for elem in temp2:\n",
    "#     temp_colname = 'ratio_{0}_{1}'.format(elem[0],elem[1])\n",
    "#     temp_colnames.append(temp_colname)\n",
    "\n",
    "# # elem = temp2[0]\n",
    "# # temp_colname = 'ratio_{0}_{1}'.format(elem[0],elem[1])\n",
    "# # temp_colnames.append(temp_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start the h2o JVM and load our data if it not already there**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5161,
     "status": "ok",
     "timestamp": 1562674411420,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "B95eXEe1PwMm",
    "outputId": "0ea04f12-897d-49b2-e266-c502514c569c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://localhost:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>5 hours 13 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 year, 2 months and 7 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_jovyan_tyjfu2</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.913 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         5 hours 13 mins\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.3\n",
       "H2O cluster version age:    1 year, 2 months and 7 days !!!\n",
       "H2O cluster name:           H2O_from_python_jovyan_tyjfu2\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.913 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.7 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<H2OConnection to http://localhost:54321, no session>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h2o.init(port=54321)\n",
    "h2o.connect(port=54321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove all data loaded in JVM\n",
    "# for key in h2o.ls()['key']:\n",
    "#     h2o.remove(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLM_model_python_1594684701152_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLM_model_python_1594734597080_110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLM_model_python_1594734597080_144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLM_model_python_1594734597080_177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLM_model_python_1594734597080_77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Key_Frame__upload_80bfcdb5206c94eb229c20208713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Key_Frame__upload_811edd1e25f74452b20e67239c29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Key_Frame__upload_822265a3340d75ec177293124680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Key_Frame__upload_920404040d2ca40a890976dc6af0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Key_Frame__upload_98b5b08c8136e3ecf9d4cbd87bb7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Key_Frame__upload_b0922737ee40c72229d3a46b53c0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>df_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>df_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594684701152_8@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594684701152_8@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594684701152_8@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594734597080_11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594734597080_11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594734597080_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594734597080_17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>modelmetrics_GLM_model_python_1594734597080_77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>predictions_9ab0_GLM_model_python_159473459708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>predictions_9e67_GLM_model_python_159473459708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>predictions_b0ee_GLM_model_python_159473459708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>py_1_sid_b0e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>py_4_sid_b0e4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  key\n",
       "0                    GLM_model_python_1594684701152_8\n",
       "1                  GLM_model_python_1594734597080_110\n",
       "2                  GLM_model_python_1594734597080_144\n",
       "3                  GLM_model_python_1594734597080_177\n",
       "4                   GLM_model_python_1594734597080_77\n",
       "5   Key_Frame__upload_80bfcdb5206c94eb229c20208713...\n",
       "6   Key_Frame__upload_811edd1e25f74452b20e67239c29...\n",
       "7   Key_Frame__upload_822265a3340d75ec177293124680...\n",
       "8   Key_Frame__upload_920404040d2ca40a890976dc6af0...\n",
       "9   Key_Frame__upload_98b5b08c8136e3ecf9d4cbd87bb7...\n",
       "10  Key_Frame__upload_b0922737ee40c72229d3a46b53c0...\n",
       "11                                            df_test\n",
       "12                                           df_train\n",
       "13  modelmetrics_GLM_model_python_1594684701152_8@...\n",
       "14  modelmetrics_GLM_model_python_1594684701152_8@...\n",
       "15  modelmetrics_GLM_model_python_1594684701152_8@...\n",
       "16  modelmetrics_GLM_model_python_1594734597080_11...\n",
       "17  modelmetrics_GLM_model_python_1594734597080_11...\n",
       "18  modelmetrics_GLM_model_python_1594734597080_14...\n",
       "19  modelmetrics_GLM_model_python_1594734597080_17...\n",
       "20  modelmetrics_GLM_model_python_1594734597080_77...\n",
       "21  predictions_9ab0_GLM_model_python_159473459708...\n",
       "22  predictions_9e67_GLM_model_python_159473459708...\n",
       "23  predictions_b0ee_GLM_model_python_159473459708...\n",
       "24                                      py_1_sid_b0e4\n",
       "25                                      py_4_sid_b0e4"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is df_train already in the JVM?\n",
    "h2o.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It if is, then just create a handle:\n",
    "# h2o_df_train = h2o.get_frame('df_train')\n",
    "# h2o_df_test = h2o.get_frame('df_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7419,
     "status": "ok",
     "timestamp": 1562674461598,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "0I1VAotDPwMu",
    "outputId": "3a7a6671-cbbf-4012-ea0b-6545ac94cd35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Otherwise run this code.\n",
    "h2o_df_train = h2o.H2OFrame(df_train[vars_ind_numeric + vars_ind_categorical + var_dep],\n",
    "                           destination_frame='df_train')\n",
    "h2o_df_test = h2o.H2OFrame(df_test[vars_ind_numeric + vars_ind_categorical],\n",
    "                           destination_frame='df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2o_df_test = h2o.H2OFrame(df_test[vars_ind_numeric + vars_ind_categorical],\n",
    "#                            destination_frame='df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change target to enum type as we are building a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1562674465147,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "AryWJbCiPwMy",
    "outputId": "065b0973-faff-4ac8-d0e7-58f2f28e05be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 'int'}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o_df_train[var_dep].types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1562674467834,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "yOF_h-uxPwM2",
    "outputId": "c4e94779-7a6d-402f-9a28-00ddba22e7af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 'enum'}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Set target type to enum\n",
    "h2o_df_train[var_dep] = h2o_df_train[var_dep].asfactor()\n",
    "h2o_df_train[var_dep].types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the features to be used**\n",
    "\n",
    "In this quick notebook, we ignore the hccv's.  For the main assigment you should deal sensibly with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NR9C_qqjPwM8"
   },
   "outputs": [],
   "source": [
    "# Need some proper way to deal with hcccv (eg target encoding).  For now just remove.\n",
    "features = vars_ind_numeric + vars_ind_categorical\n",
    "# features = [var for var in features if var not in vars_ind_hccv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([col for col in h2o_df_train2.columns if col not in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3smVMkl0PwND"
   },
   "source": [
    "**GridSearch**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have more or less randomly chosen the list below to search for min leaf size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2**idx for idx in 7+np.arange(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkF5P8slPwNE"
   },
   "outputs": [],
   "source": [
    "# hyper_params = {'min_rows' : [2**idx for idx in 7+np.arange(10)]} \n",
    "# search_criteria = {'strategy': \"Cartesian\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEZRwnhXPwNH"
   },
   "outputs": [],
   "source": [
    "# grid_dt = H2OGridSearch(\n",
    "#                     H2OGradientBoostingEstimator(\n",
    "#                         seed = 2020,   \n",
    "#                         nfolds = 5,\n",
    "#                         ntrees = 1,\n",
    "#                         max_depth = 20,\n",
    "#                         #min_rows = 1,\n",
    "#                         sample_rate = 1,\n",
    "#                         col_sample_rate = 1,\n",
    "#                         ),\n",
    "#                     grid_id = 'grid_dt',\n",
    "#                     search_criteria = search_criteria,\n",
    "#                     hyper_params = hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161896,
     "status": "ok",
     "timestamp": 1562674644668,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "uiMOtLhsPwNX",
    "outputId": "b4f8a024-476c-424a-a696-65877a6a3ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f09.F', 'f11', 'f03.F', 'f11_0', 'f11_1']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vars_mostImp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1621,
     "status": "ok",
     "timestamp": 1562674647641,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "ykL-Y4cYPwNg",
    "outputId": "c2e703df-e794-4e9c-9fbf-9a9bca3b656e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8sn8pF4PwNm"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jc2oVRaPwNn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5049,
     "status": "ok",
     "timestamp": 1562674667402,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "-zpmVw7OPwNq",
    "outputId": "1ba8889a-aee5-4ed5-eaad-85a45a58dc11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1562674669330,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "PB6fvlvIPwNu",
    "outputId": "0231113f-3fd8-490f-dc4b-bbdd9ecf9566"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lambda_search for alpha and lambda given an identity link**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "idx_h2o_train  = h2o.H2OFrame(idx_train.astype('int').values)\n",
    "idx_h2o_val    = h2o.H2OFrame(idx_val.astype('int').values)\n",
    "idx_h2o_design = h2o.H2OFrame(idx_design.astype('int').values)\n",
    "# idx_h2o_test   = h2o.H2OFrame(idx_test.astype('int').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████| 100%\n",
      "CPU times: user 6 s, sys: 344 ms, total: 6.34 s\n",
      "Wall time: 26min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### WORKING AS OF 03h50 14.07.20\n",
    "## To run GLM on categorical data, set the family to \"multinomial\" (or \"binomial\" when there are only two classes). \n",
    "# had to do the above as h2o wouldn't run model saying it wasn't getting a numeric \n",
    "# model=H2OGeneralizedLinearEstimator(  alpha=0.99\n",
    "# #                                         , family='gaussian'\n",
    "#                                         , family='binomial'\n",
    "# #                                         , link='identity'\n",
    "#                                         , link='logit'\n",
    "#                                         , lambda_search=True\n",
    "#                                         , lambda_min_ratio=1e-7\n",
    "#                                         , nlambdas=200\n",
    "#                                         , early_stopping=False\n",
    "#                                         , nfolds=10\n",
    "#                                         , seed=2020\n",
    "#                                         )\n",
    "# model.train(x=features, \n",
    "#             y='target',\n",
    "#             training_frame=h2o_df_train[idx_h2o_design, :])\n",
    "\n",
    "\n",
    "## To run GLM on categorical data, set the family to \"multinomial\" (or \"binomial\" when there are only two classes). \n",
    "# had to do the above as h2o wouldn't run model saying it wasn't getting a numeric \n",
    "\n",
    "# missing_values_handling -> MeanImputation: deals with new sample having categorical levels not seen in training. Replaces the unseen value with the most frequent level present in training.\n",
    "# Interactions-> Specifies the predictors to \n",
    "# keep_cross_valudation_* -> set to false as only concerned with best final model. Saves some memory in H2o cluster.\n",
    "model=H2OGeneralizedLinearEstimator(  alpha=0.99\n",
    "#                                         , family='gaussian'\n",
    "                                        , family='binomial'\n",
    "#                                         , link='identity'\n",
    "                                        , link='logit'\n",
    "                                        , lambda_search=True\n",
    "                                        , lambda_min_ratio=1e-7\n",
    "                                        , nlambdas=100\n",
    "                                        , early_stopping=True\n",
    "                                        , nfolds=10\n",
    "                                        , seed=2020\n",
    "                                        , keep_cross_validation_models=False\n",
    "                                        , keep_cross_validation_predictions=False\n",
    "                                        , keep_cross_validation_fold_assignment=False\n",
    "#                                         , interactions=vars_mostImp[0:2]\n",
    "                                        , missing_values_handling='mean_imputation'\n",
    "                                   )\n",
    "# model.train(x=features, \n",
    "#             y='target',\n",
    "#             training_frame=h2o_df_train[idx_h2o_train, :],\n",
    "#             validation_frame=h2o_df_train[idx_h2o_val, :])\n",
    "model.train(x=features, \n",
    "            y='target',\n",
    "            training_frame=h2o_df_train[idx_h2o_design, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM basic, no interactions, no mean imputation for missing level values in test\n",
    "# model name: GLM_model_python_1594684701152_8\n",
    "\n",
    "# GLM basic, no interactions, WITH mean imputation for missing level values in test\n",
    "# model name: GLM_model_python_1594734597080_177\n",
    "\n",
    "# GLM numerical divisons, no interactions, WITH mean imputation for missing level values in test\n",
    "# model name: GLM_model_python_1594734597080_426\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_curr = model\n",
    "# save the model\n",
    "glm_curr_path = h2o.save_model(model=glm_curr, path=dirPData, force=True)\n",
    "glm_num_meanImpute_path = glm_curr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/Projects/AmesHousing/PData/GLM_model_python_1594734597080_426'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glm_num_meanImpute_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# glm_bst_path = h2o.save_model(model=glm_curr, path=dirPData, force=True)\n",
    "# glm_bst_path\n",
    "# glm_bst_path=dirPData + 'GLM_model_python_1594684701152_8'\n",
    "glm_bst_path='/home/jovyan/Projects/final_assignment/PCode/../PData/GLM_model_python_1594684701152_8'\n",
    "glm_bst = h2o.load_model(path = glm_bst_path)  # load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e20' has levels not trained on: [30146, BE271, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e13' has levels not trained on: [Q, S]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e24' has levels not trained on: [J, M, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'e03' has levels not trained on: [J, nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'c09' has levels not trained on: [nan]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'a18' has levels not trained on: [D]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "temp_preds = model.predict(h2o_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_preds\n",
    "df_test['Predicted'] = np.round(temp_preds[2].as_data_frame(), 5)\n",
    "df_preds = df_test[['unique_id', 'Predicted']].copy()\n",
    "df_test[['unique_id', 'Predicted']].to_csv(dirPOutput + 'part1_preds_num_meanImpute_250k.csv', index=False)\n",
    "# h2o_df_train[idx_h2o_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspect coefficients\n",
    "#plot\n",
    "glm_bst.std_coef_plot(num_of_features=10)\n",
    "#get list of 5 most important variables\n",
    "vars_mostImp = [var[0] for var in glm_bst.varimp()[0:5]]\n",
    "#note that vars_mostImp is made up of onehots created by H2o and thus some aren't actually present in the train/test frames\n",
    "#we need to refer to the original variables before h2o onehots them\n",
    "vars_mostImp = [var.split('.')[0] for var in vars_mostImp] #split on the onehot delimiter and keep only the first part of the variable name (i.e. the original variable name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['f09.F']\n",
    "# [var.split('.')[0] for var in vars_mostImp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred_train = glm_bst.predict(h2o_df_train[idx_h2o_train, :])\n",
    "bst_pred_val   = glm_bst.predict(h2o_df_train[idx_h2o_val, :])\n",
    "# bst_pred_test  = glm_bst.predict(h2o_df_all[idx_h2o_test, :])\n",
    "\n",
    "bst_pred_train = bst_pred_train.as_data_frame().values.ravel()\n",
    "bst_pred_val   = bst_pred_val.as_data_frame().values.ravel()\n",
    "# bst_pred_test  = bst_pred_test.as_data_frame().values.ravel()\n",
    "\n",
    "print('train error', fn_MAE(y[idx_train], bst_pred_train))\n",
    "print('val error',   fn_MAE(y[idx_val], bst_pred_val))\n",
    "# print('test error',  fn_MAE(y[idx_test], bst_pred_test))\n",
    "\n",
    "h2o.show_progress()\n",
    "\n",
    "# AC run gives\n",
    "#train error 11950.0\n",
    "#val error 12077.0\n",
    "#test error 13667.0\n",
    "# And these should be reproduced by this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(df_test[vars_ind_numeric+vars_ind_categorical].columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_test[~df_test[['unique_id','b06']]].columns)\n",
    "# vars_notToUse\n",
    "# temp = ['unique_id','b06']\n",
    "# df_test[temp]\n",
    "# set(features) == set(vars_ind_numeric+vars_ind_categorical) #only order differs\n",
    "# len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iS_xVSanPwNy"
   },
   "source": [
    "**Create Predictions**\n",
    "\n",
    "When, the h2o tries to make predictions, we get a warning telling us that in some features there are some observations with new levels of the factors and these values were not present in the training dataset.  There is not alot we can do about this.  You should make sure you udnerstand how H2O makes predictions in such a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4864,
     "status": "ok",
     "timestamp": 1562674684502,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "LtCrxIjzPwN0",
    "outputId": "ba0778fe-2ef5-41fa-e5d1-81298892d25e"
   },
   "outputs": [],
   "source": [
    "# h2o_df_test = h2o.H2OFrame(df_test[vars_ind_numeric + vars_ind_categorical],\n",
    "#                            destination_frame='df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1562674687811,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "d9OBNXcZPwN9",
    "outputId": "ac1df6e9-3ded-415a-f081-76ccc508acd1"
   },
   "outputs": [],
   "source": [
    "preds = glm_bst.predict(h2o_df_test)\n",
    "\n",
    "# preds = model.predict(h2o_df_test)\n",
    "# There is no need to round your predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = np.round(preds[2].as_data_frame(), 5)\n",
    "df_preds = df_test[['unique_id', 'Predicted']].copy()\n",
    "df_test[['unique_id', 'Predicted']].to_csv(dirPOutput + 'part1_preds_250k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACEpxn3YPwOL"
   },
   "source": [
    "Now you can submit 04b_df_preds_dt_250k.csv on Kaggle.  You should get an AUROC of around 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If you shut down your h2o JVM in this session, then any other Python notebooks open will also loose the JVM since they all connect to the same JVM!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1562674795290,
     "user": {
      "displayName": "K a l o u",
      "photoUrl": "https://lh4.googleusercontent.com/-EYTbYeNdLqk/AAAAAAAAAAI/AAAAAAAAADk/OD6CDp5FiG4/s64/photo.jpg",
      "userId": "10262331298445208932"
     },
     "user_tz": -60
    },
    "id": "HOP3NaYBPwOO",
    "outputId": "24b4d559-3307-4b24-caef-72a637790fe0"
   },
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHLAZxx3PwOS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3smVMkl0PwND",
    "H8sn8pF4PwNm"
   ],
   "name": "*Decision Tree.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
