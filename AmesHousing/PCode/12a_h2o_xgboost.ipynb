{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames housing: xgboost with h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    " - start\n",
    " - h2o\n",
    " \n",
    "Notes\n",
    " - ** h2o does not need onehot for hccv's **\n",
    "\n",
    "Sources:\n",
    "http://ww2.amstat.org/publications/jse/v19n3/decock.pdf\n",
    "\n",
    "Copyright (C) 2018 Alan Chalk  \n",
    "Please do not distribute or publish without permission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**packages **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**directories and paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_MAE(actuals, predictions):\n",
    "    return np.round(np.mean(np.abs(predictions - actuals)))\n",
    "\n",
    "def fn_RMSE(actuals, predictions):\n",
    "    return np.round(np.sqrt(np.mean((predictions - actuals)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df_all (use the none one-hot version)\n",
    "#df_all = pd.read_hdf(dirPData + '02_df_all.h5', 'df_all')\n",
    "f_name = dirPData + '02_df.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_all = dict_['df_all']\n",
    "\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the variables information\n",
    "f_name = dirPData + '02_vars.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "var_dep = dict_['var_dep']\n",
    "vars_ind_numeric = dict_['vars_ind_numeric']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "vars_ind_onehot = dict_['vars_ind_onehot']\n",
    "\n",
    "del dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train  = df_all['fold'].isin(range(6))\n",
    "idx_val    = df_all['fold'].isin([6, 7])\n",
    "idx_design = df_all['fold'].isin(range(8))\n",
    "idx_test   = df_all['fold'].isin([8, 9])\n",
    "\n",
    "y = df_all[var_dep].values.ravel()\n",
    "y_train = y[idx_train]\n",
    "y_val = y[idx_val]\n",
    "y_design = y[idx_design]\n",
    "y_test = y[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind = vars_ind_categorical + vars_ind_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init()\n",
    "#h2o.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send data to h2o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_df_all = h2o.H2OFrame(df_all[vars_ind + var_dep + ['fold']],\n",
    "                         destination_frame = 'df_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_h2o_train  = h2o.H2OFrame(idx_train.astype('int').values)\n",
    "idx_h2o_val    = h2o.H2OFrame(idx_val.astype('int').values)\n",
    "idx_h2o_design = h2o.H2OFrame(idx_design.astype('int').values)\n",
    "idx_h2o_test   = h2o.H2OFrame(idx_test.astype('int').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One xgboost model**\n",
    "\n",
    " - example with a relatively small number of trees and a large learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "      \"ntrees\" : 200\n",
    "    , \"max_depth\" : 6\n",
    "    , \"learn_rate\" : 0.02\n",
    "    , \"sample_rate\" : 0.7\n",
    "    , \"col_sample_rate_per_tree\" : 0.9\n",
    "    , \"min_rows\" : 10\n",
    "    , \"seed\": 2019\n",
    "    #, \"feature_fraction_seed\": 2019\n",
    "    , \"stopping_metric\": 'mae'\n",
    "    , \"stopping_rounds\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = H2OXGBoostEstimator(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x=vars_ind, \n",
    "            y='saleprice',\n",
    "            training_frame=h2o_df_all[idx_h2o_train, :],\n",
    "            validation_frame=h2o_df_all[idx_h2o_val, :]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.no_progress()\n",
    "\n",
    "pred_train = model.predict(h2o_df_all[idx_h2o_train, :])\n",
    "pred_val   = model.predict(h2o_df_all[idx_h2o_val, :])\n",
    "#pred_test  = model.predict(h2o_df_all[idx_h2o_test, :])\n",
    "\n",
    "pred_train = pred_train.as_data_frame().values.ravel()\n",
    "pred_val   = pred_val.as_data_frame().values.ravel()\n",
    "#pred_test  = pred_test.as_data_frame().values.ravel()\n",
    "\n",
    "print('train error', fn_MAE(y[idx_train], pred_train))\n",
    "print('val error',   fn_MAE(y[idx_val],   pred_val))\n",
    "#print('test error',  fn_MAE(y[idx_test],  pred_test))\n",
    "\n",
    "h2o.show_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and validation curves**\n",
    "\n",
    "We can see that more trees are certainly necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scoring_history = model.scoring_history()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(df_scoring_history['number_of_trees'],\n",
    "         df_scoring_history['training_mae'],\n",
    "         'k-',\n",
    "         label='training')\n",
    "ax1.plot(df_scoring_history['number_of_trees'],\n",
    "         df_scoring_history['validation_mae'],\n",
    "         'r-',\n",
    "         label='validation')\n",
    "ax1.set_xlabel('number of trees', fontsize=20)\n",
    "ax1.set_ylabel('mae', fontsize=20)\n",
    "_ = ax1.legend(fontsize=20)\n",
    "#ax1.set_ylim([0, 50000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random grid search\n",
    "\n",
    "There are at least 3 hyper-parameters we should look at:\n",
    " - sample_rate\n",
    " - col_sample_rate_per_tree\n",
    " - min_rows\n",
    " \n",
    "If we try 5 of each in a grid search - this is 125 forests to grow and test - which will take a while.\n",
    "\n",
    "Rather we will randomly sample the grid and limit our compute effort to 10 forests.\n",
    "\n",
    "How good is random grid search?  See for example http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [5, 6, 7, 8, 9]\n",
    "sample_rate = [0.1, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "min_rows = [2, 5, 10, 20, 40]\n",
    "\n",
    "n_iter = len(max_depth) * len(sample_rate) * len(min_rows)\n",
    "\n",
    "params = np.array(np.meshgrid(max_depth, sample_rate, min_rows)).reshape(3, n_iter).T\n",
    "\n",
    "df_results = pd.DataFrame(params, columns = ['max_depth', 'sample_rate', 'min_rows'])\n",
    "df_results['train_mae'] = np.nan\n",
    "df_results['val_mae'] = np.nan\n",
    "df_results['train_rmse'] = np.nan\n",
    "df_results['val_rmse'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all and find train and val mae\n",
    "\n",
    "n_models = 20\n",
    "\n",
    "for idx in range(n_models):\n",
    "    \n",
    "    print(idx, 'of', n_models)\n",
    "        \n",
    "    max_depth = int(df_results.iloc[idx]['max_depth'])\n",
    "    sample_rate = df_results.iloc[idx]['sample_rate']\n",
    "    min_rows = df_results.iloc[idx]['min_rows']\n",
    "    \n",
    "    param = {\n",
    "      \"ntrees\" : 2000 # really need something like 2000 for eta 0.002\n",
    "    , \"max_depth\" : max_depth\n",
    "    , \"learn_rate\" : 0.002\n",
    "    , \"sample_rate\" : sample_rate\n",
    "    , \"col_sample_rate_per_tree\" : 0.9\n",
    "    , \"min_rows\" : min_rows\n",
    "    , \"seed\": 2018\n",
    "    , \"score_tree_interval\": 100\n",
    "    , \"stopping_metric\": 'mae'\n",
    "    , \"stopping_rounds\": 20\n",
    "}\n",
    "    \n",
    "    model = H2OXGBoostEstimator(**param)\n",
    "    \n",
    "    model.train(x=vars_ind, \n",
    "            y='saleprice',\n",
    "            training_frame=h2o_df_all[idx_h2o_train, :],\n",
    "            validation_frame=h2o_df_all[idx_h2o_val, :]\n",
    "            )\n",
    "\n",
    "    model_pred_train = model.predict(h2o_df_all[idx_h2o_train, :])\n",
    "    model_pred_val   = model.predict(h2o_df_all[idx_h2o_val, :])\n",
    "    \n",
    "    model_pred_train = model_pred_train.as_data_frame().values.ravel()\n",
    "    model_pred_val   = model_pred_val.as_data_frame().values.ravel()\n",
    "\n",
    "    df_results['train_mae'].iloc[idx] = fn_MAE(y[idx_train], model_pred_train)\n",
    "    df_results['val_mae'].iloc[idx]   = fn_MAE(y[idx_val], model_pred_val)\n",
    "    df_results['train_rmse'].iloc[idx] = fn_RMSE(y[idx_train], model_pred_train)\n",
    "    df_results['val_rmse'].iloc[idx]   = fn_RMSE(y[idx_val], model_pred_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.dropna(axis=0, inplace = True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmin = df_results['val_mae'].idxmin()\n",
    "print(df_results.iloc[idxmin])\n",
    "# output when run last\n",
    "# max_depth          7.0\n",
    "# sample_rate        0.6\n",
    "# min_rows           2.0\n",
    "\n",
    "# train_mae       8157\n",
    "# val_mae        14472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - I don't like the min_rows 2 paramter.  \n",
    " - Nor do I believe it (that you can move in a direction defined by two house prices)\n",
    " - I would always prefer something which does not overfit the data by too much - and this gap (8000 - 14000) is much too big.\n",
    " - The extract below shows that at max_depth of 7, the two runs with similar sample rates (0.6 and 0.8) have similar val_mae but the one with min-rows 10 has much less overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['max_depth'] == 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgboost with best hyper-parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "      \"ntrees\" : 2000 \n",
    "    , \"max_depth\" : 7\n",
    "    , \"learn_rate\" : 0.002\n",
    "    , \"sample_rate\" : 0.6\n",
    "    , \"col_sample_rate_per_tree\" : 0.9\n",
    "    , \"min_rows\" : 40\n",
    "    , \"seed\": 2019\n",
    "    , \"score_tree_interval\": 100\n",
    "    , \"stopping_metric\": 'mae'\n",
    "    , \"stopping_rounds\": 20\n",
    "}\n",
    "\n",
    "xg_bst = H2OXGBoostEstimator(**param)\n",
    "\n",
    "xg_bst.train(x=vars_ind, \n",
    "             y='saleprice',\n",
    "             training_frame=h2o_df_all[idx_h2o_design, :]\n",
    "          )\n",
    "\n",
    "\n",
    "bst_pred_train = xg_bst.predict(h2o_df_all[idx_h2o_train, :])\n",
    "bst_pred_val   = xg_bst.predict(h2o_df_all[idx_h2o_val, :])\n",
    "bst_pred_test  = xg_bst.predict(h2o_df_all[idx_h2o_test, :])\n",
    "\n",
    "bst_pred_train = bst_pred_train.as_data_frame().values.ravel()\n",
    "bst_pred_val   = bst_pred_val.as_data_frame().values.ravel()\n",
    "bst_pred_test  = bst_pred_test.as_data_frame().values.ravel()\n",
    "\n",
    "print('train error', fn_MAE(y[idx_train], bst_pred_train))\n",
    "print('val error',   fn_MAE(y[idx_val], bst_pred_val))\n",
    "print('test error',  fn_MAE(y[idx_test], bst_pred_test))\n",
    "\n",
    "#       last run gave  RF with leafsize 20\n",
    "#             xgb          was\n",
    "#train error 10,073       13,544\n",
    "#val error    9,944       13,696\n",
    "#test error  13,079       14,801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_bst_path = h2o.save_model(model=xg_bst, path=dirPData, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_bst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_bst = h2o.load_model(path = xg_bst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save predictions and model information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions file\n",
    "\n",
    "#store = pd.HDFStore(dirPData + 'predictions.h5')\n",
    "#df_predictions = pd.read_hdf(store, 'df_predictions')\n",
    "#store.close()\n",
    "\n",
    "f_name = dirPData + 'dict_predictions.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_predictions = dict_['df_predictions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['m_3a']  = xg_bst.predict(h2o_df_all).as_data_frame().values.ravel()\n",
    "dict_['df_predictions'] = df_predictions\n",
    "dict_['m_3a'] = 'xgboost, saved as m_3a'\n",
    "dict_['m_3a_path'] = xg_bst_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + 'dict_predictions.pickle'\n",
    "\n",
    "with open(f_name, \"wb\") as f:\n",
    "    pickle.dump(dict_, f)\n",
    "    \n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
