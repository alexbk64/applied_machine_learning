{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames housing: penalised regression with h2o and category encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    " - start\n",
    " - basis functions\n",
    " - Various encoders\n",
    " - regression with h2o\n",
    " - save model and save predictions\n",
    " \n",
    "Notes\n",
    "\n",
    "\n",
    "Sources:\n",
    " - \n",
    "\n",
    "Copyright (C) 2018 Alan Chalk  \n",
    "Please do not distribute or publish without permission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directories and paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData =   \"../PData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_MAE(actuals, predictions):\n",
    "    return np.round(np.mean(np.abs(predictions - actuals)))\n",
    "\n",
    "def fn_RMSE(actuals, predictions):\n",
    "    return np.round(np.sqrt(np.mean((predictions - actuals)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**\n",
    "\n",
    "Do not use the one-hot version!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = dirPData + '02_df.pickle'\n",
    "\n",
    "with (open(f_name, \"rb\")) as f:\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_all = dict_['df_all']\n",
    "\n",
    "#del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the variables information\n",
    "f_name = dirPData + '02_vars.pickle'\n",
    "with open(f_name, \"rb\") as f:\n",
    "    dict_ = pickle.load(f)\n",
    "    \n",
    "var_dep              = dict_['var_dep']\n",
    "vars_ind_numeric     = dict_['vars_ind_numeric']\n",
    "vars_ind_categorical = dict_['vars_ind_categorical']\n",
    "\n",
    "del dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train  = df_all['fold'].isin(range(6))\n",
    "idx_val    = df_all['fold'].isin([6, 7])\n",
    "idx_design = df_all['fold'].isin(range(8))\n",
    "idx_test   = df_all['fold'].isin([8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare basis functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this only for truly continuous variables\n",
    "# (this is not necessarily \"right\" - but just quicker to code ...)\n",
    "# using >8 made sklearn crash - but h2o is fine with it\n",
    "vars_ind_tospline = df_all[vars_ind_numeric].columns[(df_all[vars_ind_numeric].nunique() > 8)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_tosplines(x):\n",
    "    x = x.values\n",
    "    # hack: remove zeros to avoid issues where lots of values are zero\n",
    "    x_nonzero = x[x != 0]\n",
    "    ptiles = np.percentile(x_nonzero, [10, 20, 40, 60, 80, 90])\n",
    "    ptiles = np.unique(ptiles)\n",
    "    print(var, ptiles)\n",
    "    df_ptiles = pd.DataFrame({var: x})\n",
    "    for idx, ptile in enumerate(ptiles):\n",
    "        df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "    return(df_ptiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update df_all with splines / basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_ind_tospline:\n",
    "    df_ptiles = fn_tosplines(df_all[var])\n",
    "    df_all.drop(columns=[var], inplace=True)\n",
    "    vars_ind_numeric.remove(var)\n",
    "    df_all = pd.concat([df_all, df_ptiles], axis=1, sort=False)\n",
    "    vars_ind_numeric.extend(df_ptiles.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind = vars_ind_categorical + vars_ind_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience store dependent variable as y\n",
    "y = df_all[var_dep].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HCCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do something for neighborhood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[vars_ind_categorical].nunique().sort_values(ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['neighborhood_cat'] = df_all['neighborhood']\n",
    "y_train = y[idx_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[idx_train].copy()\n",
    "\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "enc.fit(df_train[['neighborhood_cat']]) # Note the double square brackets to preserve the DataFrame type\n",
    "arr_enc = enc.transform(df_train[['neighborhood_cat']])\n",
    "df_train['neighborhood'] = arr_enc\n",
    "\n",
    "df_train[['neighborhood_cat', 'neighborhood']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df_train['neighborhood'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[idx_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['neighborhood_cat', 'saleprice']].groupby(['neighborhood_cat']).agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = TargetEncoder(cols=['neighborhood'])\n",
    "\n",
    "df_encoded = enc.fit_transform(df_train, y_train)\n",
    "df_encoded[['neighborhood_cat', 'neighborhood']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the transformation of the training data with the supervised methods, you should use fit_transform() method instead of fit().transform(), because these two methods do not have to generate the same result. The difference can be observed with LeaveOneOut encoder, which performs a nested cross-validation for the training data in fit_transform() method (to decrease over-fitting of the downstream model) but uses all the training data for scoring with transform() method (to get as accurate estimates as possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BinaryEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[idx_train].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = BinaryEncoder(cols=['neighborhood_cat'])\n",
    "\n",
    "enc.fit(df_train[['neighborhood_cat']])\n",
    "df_encoded = enc.transform(df_train[['neighborhood_cat']])\n",
    "df_encoded['neighborhood_cat'] = df_train['neighborhood_cat']\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hash encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[idx_train].copy()\n",
    "df_train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = HashingEncoder(cols=['neighborhood_cat'], n_components=3)\n",
    "\n",
    "enc.fit(df_train[['neighborhood_cat']])\n",
    "df_encoded = enc.transform(df_train[['neighborhood_cat']])\n",
    "df_encoded['neighborhood_cat'] = df_train['neighborhood_cat']\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LeaveOneOutEncoder**\n",
    "\n",
    "I will try this one here - you should experiment with as many of them as you have time for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LeaveOneOutEncoder(cols=vars_ind_categorical, sigma=0.3)\n",
    "enc.fit(df_all[idx_design], y[idx_design]) # should really use fit_transform\n",
    "df_temp = enc.transform(df_all)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"elastic net\" regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**start h2o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.init(port=54321)\n",
    "#h2o.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data into h2o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_df_all = h2o.H2OFrame(df_all[vars_ind + var_dep + ['fold']],\n",
    "                          destination_frame = 'df_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_h2o_train  = h2o.H2OFrame(idx_train.astype('int').values)\n",
    "idx_h2o_val    = h2o.H2OFrame(idx_val.astype('int').values)\n",
    "idx_h2o_design = h2o.H2OFrame(idx_design.astype('int').values)\n",
    "idx_h2o_test   = h2o.H2OFrame(idx_test.astype('int').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lambda_search for alpha and lambda given an identity link**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=H2OGeneralizedLinearEstimator(  alpha=0.99\n",
    "                                        , family='gaussian'\n",
    "                                        , link='identity'\n",
    "                                        , lambda_search=True\n",
    "                                        , lambda_min_ratio=1e-7\n",
    "                                        , nlambdas=200\n",
    "                                        , early_stopping=False\n",
    "                                        , nfolds=10)\n",
    "model.train(x=vars_ind, \n",
    "            y='saleprice',\n",
    "            training_frame=h2o_df_all[idx_h2o_design, :])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_bst = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_pred_train = glm_bst.predict(h2o_df_all[idx_h2o_train, :])\n",
    "bst_pred_val   = glm_bst.predict(h2o_df_all[idx_h2o_val, :])\n",
    "bst_pred_test  = glm_bst.predict(h2o_df_all[idx_h2o_test, :])\n",
    "\n",
    "bst_pred_train = bst_pred_train.as_data_frame().values.ravel()\n",
    "bst_pred_val   = bst_pred_val.as_data_frame().values.ravel()\n",
    "bst_pred_test  = bst_pred_test.as_data_frame().values.ravel()\n",
    "\n",
    "print('train error', fn_MAE(y[idx_train], bst_pred_train))\n",
    "print('val error',   fn_MAE(y[idx_val], bst_pred_val))\n",
    "print('test error',  fn_MAE(y[idx_test], bst_pred_test))\n",
    "\n",
    "h2o.show_progress()\n",
    "\n",
    "# AC run gives\n",
    "#train error 11950.0\n",
    "#val error 12077.0\n",
    "#test error 13667.0\n",
    "# And these should be reproduced by this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
