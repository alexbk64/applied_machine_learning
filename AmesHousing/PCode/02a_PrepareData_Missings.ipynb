{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data - Ames Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    " - start\n",
    "  - packages\n",
    "  - directories and paths\n",
    " - data manipulation\n",
    "   - variables to use\n",
    "   - dealing with missings and outliers\n",
    " - save data\n",
    "\n",
    "Sources:\n",
    "http://ww2.amstat.org/publications/jse/v19n3/decock.pdf\n",
    "\n",
    "Copyright (C) 2018 Alan Chalk  \n",
    "Please do not distribute or publish without permission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**Import any packages needed** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AC using an image (27-25-2019) with sklearn 0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set directories and paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Projects/AmesHousing/PCode\n"
     ]
    }
   ],
   "source": [
    "# Set directories\n",
    "print(os.getcwd())\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\"\n",
    "dirPOutput = \"../POutput/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store = pd.HDFStore(dirPData + '01_df_all.h5')\n",
    "#df_all = pd.read_hdf(store, 'df_all')\n",
    "#store.close()\n",
    "\n",
    "f_name = dirPData + '01_df_all.pickle'\n",
    "\n",
    "with open(f_name, \"rb\") as f: #read binary as f\n",
    "    dict_ = pickle.load(f)\n",
    "\n",
    "df_all = dict_['df_all']\n",
    "del f_name, dict_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>pid</th>\n",
       "      <th>ms_subclass</th>\n",
       "      <th>ms_zoning</th>\n",
       "      <th>lot_frontage</th>\n",
       "      <th>lot_area</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lot_shape</th>\n",
       "      <th>land_contour</th>\n",
       "      <th>...</th>\n",
       "      <th>screen_porch</th>\n",
       "      <th>pool_area</th>\n",
       "      <th>fence</th>\n",
       "      <th>misc_feature</th>\n",
       "      <th>misc_val</th>\n",
       "      <th>mo_sold</th>\n",
       "      <th>yr_sold</th>\n",
       "      <th>sale_type</th>\n",
       "      <th>sale_condition</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>MS_20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>MS_20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>MS_20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>MS_20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>MS_60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>DoesNotHaveOne</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order        pid ms_subclass ms_zoning  lot_frontage  lot_area street  \\\n",
       "0      1  526301100       MS_20        RL         141.0   31770.0   Pave   \n",
       "1      2  526350040       MS_20        RH          80.0   11622.0   Pave   \n",
       "2      3  526351010       MS_20        RL          81.0   14267.0   Pave   \n",
       "3      4  526353030       MS_20        RL          93.0   11160.0   Pave   \n",
       "4      5  527105010       MS_60        RL          74.0   13830.0   Pave   \n",
       "\n",
       "            alley lot_shape land_contour    ...     screen_porch pool_area  \\\n",
       "0  DoesNotHaveOne       IR1          Lvl    ...              0.0       0.0   \n",
       "1  DoesNotHaveOne       Reg          Lvl    ...            120.0       0.0   \n",
       "2  DoesNotHaveOne       IR1          Lvl    ...              0.0       0.0   \n",
       "3  DoesNotHaveOne       Reg          Lvl    ...              0.0       0.0   \n",
       "4  DoesNotHaveOne       IR1          Lvl    ...              0.0       0.0   \n",
       "\n",
       "            fence    misc_feature misc_val mo_sold yr_sold  sale_type  \\\n",
       "0  DoesNotHaveOne  DoesNotHaveOne      0.0     5.0  2010.0         WD   \n",
       "1           MnPrv  DoesNotHaveOne      0.0     6.0  2010.0         WD   \n",
       "2  DoesNotHaveOne  DoesNotHaveOne  12500.0     6.0  2010.0         WD   \n",
       "3  DoesNotHaveOne  DoesNotHaveOne      0.0     4.0  2010.0         WD   \n",
       "4           MnPrv  DoesNotHaveOne      0.0     3.0  2010.0         WD   \n",
       "\n",
       "   sale_condition  saleprice  \n",
       "0          Normal   215000.0  \n",
       "1          Normal   105000.0  \n",
       "2          Normal   172000.0  \n",
       "3          Normal   244000.0  \n",
       "4          Normal   189900.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables to use**\n",
    "\n",
    "Define the variables to use and not to use.  In this project we are not going to use order or pid to predict and so they are put in the list \"vars_notToUse\".  \n",
    "\n",
    "Create the following variables:\n",
    " - vars_all: an np.ndarray of column names\n",
    " - var_dep: a list containing the dependent variable ('saleprice')\n",
    " - vars_notToUse: a list of variables not to use ('order' and 'pid')\n",
    " - vars_ind: a list of variables to use being all the variables in vars_all except vars_notToUse and var_dep i.e. the independent vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = df_all.columns.values\n",
    "var_dep = ['saleprice']\n",
    "\n",
    "vars_notToUse = ['order','pid']\n",
    "#use list comprehension (see below examples)\n",
    "vars_ind = [var for var in vars_all if var not in (vars_notToUse+var_dep)] #as in second list comprehension example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "###example of list comprehensions\n",
    "numbers = range(10)\n",
    "print([number for number in numbers]) #gives list\n",
    "print([number for number in numbers if number % 2 == 0]) #gives list excluding odd nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'pear']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###another example\n",
    "lst = ['apple','pear','rabbit']\n",
    "[word for word in lst if 't' not in word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create:\n",
    " - vars_ind_numeric: A list of the numeric independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all[vars_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind_numeric = [var for var in vars_ind if df_all[var].dtype != 'object']\n",
    "# df_all[vars_ind_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deal with missing data**\n",
    "\n",
    "Dealing with missing data is a major topic in machine learning.  We will take the simplest approach.  Delete it.\n",
    "\n",
    "If a feature has mostly missing values - we will simply delete the feature (i.e. that column of the data).\n",
    "\n",
    "If a feature is mostly populated and there are just one or two records with missing values - we will delete the records.\n",
    "\n",
    "TODO \n",
    "\n",
    "Carry out the following:\n",
    " - print the number of rows and columns in the data\n",
    " - find the number of missings of each feature (df_all.isnull() gives missings and you can then use .sum(axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 80)\n",
      "lot_frontage      490\n",
      "mas_vnr_area       23\n",
      "bsmtfin_sf_1        1\n",
      "bsmtfin_sf_2        1\n",
      "bsmt_unf_sf         1\n",
      "total_bsmt_sf       1\n",
      "bsmt_full_bath      2\n",
      "bsmt_half_bath      2\n",
      "garage_yr_blt     159\n",
      "garage_cars         1\n",
      "garage_area         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)\n",
    "#collapse axis = 0 i.e. sum missing values,\n",
    "#store as series\n",
    "# df_all.isnull()\n",
    "srs_missing = df_all.isnull().sum(axis=0) \n",
    "print(srs_missing[srs_missing>0]) #show which features have missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO \n",
    "\n",
    "- You should have found above that ['lot_frontage', 'garage_yr_blt', 'mas_vnr_area'] have a reasonable number of missings. Drop these columns (inplace).\n",
    "- Remove these 3 variables from vars_ind and vars_ind_numeric\n",
    "- Then delete any remaining examples with missing features\n",
    "- Check the number of rows and columns of the remaining data - is it what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2930, 77)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###DROP VARIABLES\n",
    "vars_toDrop = ['lot_frontage', 'garage_yr_blt', 'mas_vnr_area']\n",
    "###FOR DEBUGGING, check indiv. data types of vars to drop\n",
    "# print(df_all['lot_frontage'].dtype)\n",
    "# print(df_all['garage_yr_blt'].dtype)\n",
    "# print(df_all['mas_vnr_area'].dtype)\n",
    "###ALTERNATIVELY, check all at once\n",
    "# [df_all[var].dtype for var in vars_toDrop]\n",
    "df_all.drop(labels=vars_toDrop,\n",
    "            axis=1,\n",
    "            inplace=True)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "35\n",
      "74\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "###REMOVE DROPPED VARS FROM vars_ind AND vars_ind_numeric\n",
    "print(len(vars_ind))\n",
    "print(len(vars_ind_numeric))\n",
    "###EASIEST WAY: redefine both lists according to updated df_all\n",
    "vars_ind = [var for var in vars_ind if var in df_all]\n",
    "vars_ind_numeric = [var for var in vars_ind if df_all[var].dtype!='object']\n",
    "###ALTERNATIVELY: use set differences\n",
    "#first turn list into set, then use differences, and turn it back into a list\n",
    "# list(set(vars_ind).difference(set(vars_toDrop)))\n",
    "# list(set(vars_ind_numeric).difference(set(vars_toDrop)))\n",
    "print(len(vars_ind))\n",
    "print(len(vars_ind_numeric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty series? True\n",
      "(2927, 77)\n"
     ]
    }
   ],
   "source": [
    "# now drop the NA\n",
    "df_all.dropna(axis=0,how='any', inplace=True)\n",
    "temp = df_all.isnull().sum(axis=0) \n",
    "print('Empty series?', temp[temp>0].empty) #double check all missings are gone (expect empty series)\n",
    "print(df_all.shape) #check no. of cols and rows to see if match what is expected\n",
    "del temp #no need to keep variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove known outliers**\n",
    "\n",
    "See http://ww2.amstat.org/publications/jse/v19n3/decock.pdf which states:\n",
    "        \n",
    "> I would recommend removing any houses with more than 4000 square feet from the data set (which eliminates these five unusual observations) before assigning it to students.\n",
    "\n",
    "TODO \n",
    "\n",
    "Remove the 5 examples where gr_liv_area > 4000 and check the number of rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[df_all['gr_liv_area']<=4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2922, 77)\n"
     ]
    }
   ],
   "source": [
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Care is needed with the index**\n",
    "\n",
    "- Run the line of code below - note that the index for examples (rows) is not contiguous.  Why not?\n",
    "\n",
    "Ans: Possibly because of having dropped examples and not reset index?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1340, 1495, 1756, 1762, 2174, 2228]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1339, 1340, 1342, 1343, 1344, 1345])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.where(np.diff(df_all.index.values, 1) != 1))\n",
    "df_all.index.values[1339:1345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the advantage of leaving it like this?\n",
    "Ans: can see easily which examples have been dropped \n",
    "- Reset the index (inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(drop=True, inplace=True)\n",
    "# print(np.where(np.diff(df_all.index.values, 1) != 1))\n",
    "# df_all.index.values[1339:1345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that missings is no longer an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#NOTE I ALREADY DID THIS ABOVE, BUT LEAVE PROF's CODE IN HERE ANYWAY\n",
    "srs_missing = df_all.isnull().sum(axis=0)\n",
    "print(srs_missing[srs_missing > 0])\n",
    "del srs_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the dataset and relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if you have run the store commands and for some reason they failed - you may need to run: store.close() \n",
    "# Note: When running the first time you do not to use: store.remove()\n",
    "#store = pd.HDFStore(dirPData + '02_df_all.h5')\n",
    "#store.remove('df_all')\n",
    "#df_all.to_hdf(store, 'df_all')\n",
    "#store.close()\n",
    "\n",
    "dict_ = {'df_all': df_all}\n",
    "\n",
    "f_name = dirPData + '02_df.pickle'\n",
    "with open(f_name, \"wb\") as f: #open file, write binary\n",
    "    pickle.dump(dict_, f)\n",
    "del f_name, dict_\n",
    "\n",
    "###ALSO creating a dictionary with info about variables (which not to use, which are numeric and which is dependent)\n",
    "dict_ = {'vars_ind_numeric': vars_ind_numeric,\n",
    "        'vars_notToUse': vars_notToUse,\n",
    "        'var_dep': var_dep}\n",
    "###STORE in seperate file called 02_vars\n",
    "f_name = dirPData + '02_vars.pickle'\n",
    "with open(f_name, \"wb\") as f:\n",
    "    pickle.dump(dict_, f)\n",
    "del f_name, dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
