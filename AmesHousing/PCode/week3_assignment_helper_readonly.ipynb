{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames housing: Elastic net with sklearn\n",
    "\n",
    "### Week 3 assignment - starter notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    " - Start_. Import packages, create functions and load data\n",
    " - Develop a solution\n",
    "  - Data manipulation - relevant code copied from 02a and 02b\n",
    "  - Model\n",
    "    - fit model using ElasticNetCV\n",
    "    - A quick look at the coefficients\n",
    "    - predictions\n",
    "    - performance\n",
    " - Transfer the solution to a function\n",
    " - Test the function\n",
    " - Copy the function to a .py file\n",
    "\n",
    "Copyright (C) 2020 Alan Chalk  \n",
    "Please do not distribute or publish without permission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directories and paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "dirRawData = \"../input/\"\n",
    "dirPData   = \"../PData/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_MAE(actuals, predictions):\n",
    "    return np.round(np.mean(np.abs(predictions - actuals)), 0)\n",
    "\n",
    "def fn_RMSE(actuals, predictions):\n",
    "    return np.round(np.sqrt(np.mean((predictions - actuals)**2)), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**\n",
    "\n",
    "We will just load the raw data and not do any manipulation here.  Our function will take df_all create here as input.  Whatever data manipulation we do decide to do, will become part of our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_dtypes = {'Order': np.int64,\n",
    "             'PID': np.int64,\n",
    "             'MS.SubClass': np.object,\n",
    "             'MS.Zoning': np.object,\n",
    "             'Lot.Frontage': np.float64,\n",
    "             'Lot.Area': np.float64,\n",
    "             'Street': np.object, \n",
    "             'Alley': np.object, \n",
    "             'Lot.Shape': np.object, \n",
    "             'Land.Contour': np.object,  \n",
    "             'Lot.Config': np.object,\n",
    "             'Land.Slope': np.object,\n",
    "             'Neighborhood': np.object,\n",
    "             'Condition.1': np.object,\n",
    "             'Condition.2': np.object,\n",
    "             'Bldg.Type': np.object,\n",
    "             'House.Style': np.object,\n",
    "             'Overall.Qual': np.float64,\n",
    "             'Overall.Cond': np.float64,\n",
    "             'Year.Built': np.float64,\n",
    "             'Year.Remod.Add': np.float64,\n",
    "             'Roof.Style': np.object,\n",
    "             'Roof.Matl': np.object,\n",
    "             'Exterior.1st': np.object,\n",
    "             'Exterior.2nd': np.object,\n",
    "             'Mas.Vnr.Type': np.object,\n",
    "             'Mas.Vnr.Area': np.float64,\n",
    "             'Exter.Qual': np.object,\n",
    "             'Exter.Cond': np.object,\n",
    "             'Foundation': np.object, \n",
    "             'Bsmt.Qual': np.object,\n",
    "             'Bsmt.Cond': np.object,\n",
    "             'Bsmt.Exposure': np.object,\n",
    "             'BsmtFin.Type.1': np.object,\n",
    "             'BsmtFin.SF.1': np.float64,\n",
    "             'BsmtFin.Type.2': np.object,\n",
    "             'BsmtFin.SF.2': np.float64,\n",
    "             'Bsmt.Unf.SF': np.float64,\n",
    "             'Total.Bsmt.SF': np.float64,\n",
    "             'Heating': np.object,\n",
    "             'Heating.QC': np.object,\n",
    "             'Central.Air': np.object,\n",
    "             'Electrical': np.object,\n",
    "             'X1st.Flr.SF': np.float64,\n",
    "             'X2nd.Flr.SF': np.float64,\n",
    "             'Low.Qual.Fin.SF': np.float64,\n",
    "             'Gr.Liv.Area': np.float64, \n",
    "             'Bsmt.Full.Bath': np.float64,\n",
    "             'Bsmt.Half.Bath': np.float64,\n",
    "             'Full.Bath': np.float64,\n",
    "             'Half.Bath': np.float64,\n",
    "             'Bedroom.AbvGr': np.float64,\n",
    "             'Kitchen.AbvGr': np.float64,\n",
    "             'Kitchen.Qual': np.object,\n",
    "             'TotRms.AbvGrd': np.float64, \n",
    "             'Functional': np.object, \n",
    "             'Fireplaces': np.float64, \n",
    "             'Fireplace.Qu': np.object,\n",
    "             'Garage.Type': np.object, \n",
    "             'Garage.Yr.Blt': np.float64,\n",
    "             'Garage.Finish': np.object,\n",
    "             'Garage.Cars': np.float64,\n",
    "             'Garage.Area': np.float64, \n",
    "             'Garage.Qual': np.object, \n",
    "             'Garage.Cond': np.object, \n",
    "             'Paved.Drive': np.object,\n",
    "             'Wood.Deck.SF': np.float64,\n",
    "             'Open.Porch.SF': np.float64,\n",
    "             'Enclosed.Porch': np.float64, \n",
    "             'X3Ssn.Porch': np.float64,\n",
    "             'Screen.Porch': np.float64,\n",
    "             'Pool.Area': np.float64,\n",
    "             'Fence': np.object,\n",
    "             'Misc.Feature': np.object,\n",
    "             'Misc.Val': np.float64,\n",
    "             'Mo.Sold': np.float64, \n",
    "             'Yr.Sold': np.float64,\n",
    "             'Sale.Type': np.object,\n",
    "             'Sale.Condition': np.object,\n",
    "             'SalePrice': np.float64}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(dirRawData + 'AmesHousing.txt', \n",
    "                     sep=\" \",\n",
    "                     dtype = ames_dtypes,\n",
    "                     na_values = 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work from here onwards will become part of our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names to closer to camel case\n",
    "import re\n",
    "def convert(name):\n",
    "    s1 = re.sub('\\.', '_', name)\n",
    "    return s1.lower()\n",
    "\n",
    "colnames = df_all.columns.values\n",
    "colnames = list(map(convert, colnames))\n",
    "df_all.columns = colnames\n",
    "del convert, colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "vars_all = df_all.columns.values\n",
    "var_dep = ['saleprice']\n",
    "\n",
    "vars_notToUse = ['order', 'pid']\n",
    "vars_ind = [var for var in vars_all if var not in (vars_notToUse + var_dep)]\n",
    "vars_ind_numeric = list(df_all[vars_ind].columns[df_all[vars_ind].dtypes != 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with missings as per 02a\n",
    "vars_toDrop = ['lot_frontage', 'garage_yr_blt', 'mas_vnr_area']\n",
    "df_all.drop(labels=vars_toDrop,\n",
    "            axis=1,\n",
    "            inplace=True)\n",
    "\n",
    "vars_ind = [var for var in vars_ind if var not in vars_toDrop]\n",
    "vars_ind_numeric = [var for var in vars_ind_numeric if var not in vars_toDrop]\n",
    "df_all.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "df_all = df_all[df_all['gr_liv_area'] <= 4000]\n",
    "df_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create onehot columns\n",
    "vars_ind_categorical = df_all.columns[df_all.dtypes == 'object'].tolist()\n",
    "vars_ind_onehot = []\n",
    "\n",
    "df_all_onehot = df_all.copy()\n",
    "\n",
    "for col in vars_ind_categorical:\n",
    "    \n",
    "    # use pd.get_dummies on  df_all[col] \n",
    "    df_oh = pd.get_dummies(df_all[col], drop_first=False)\n",
    "    \n",
    "    # Find the name of the most frequent column \n",
    "    col_mostFreq = df_oh.sum(axis = 0).idxmax()\n",
    "\n",
    "    # Drop the column of the most frequent category (using df_oh.drop)\n",
    "    df_oh = df_oh.drop(col_mostFreq, axis=1)\n",
    "            \n",
    "    # Rename the columns to have the original variable name as a prefix\n",
    "    oh_names = col + '_' + df_oh.columns\n",
    "    df_oh.columns = oh_names\n",
    "    \n",
    "    df_all_onehot = pd.concat([df_all_onehot, df_oh], axis = 1, sort = False)\n",
    "\n",
    "    del df_all_onehot[col]\n",
    "    vars_ind_onehot.extend(oh_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fold\n",
    "rng = np.random.RandomState(2018)\n",
    "fold = rng.randint(0, 10, df_all.shape[0])\n",
    "df_all_onehot['fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename df_all_onehot to df_all as this is now the data we will be using for \n",
    "# the rest of this work\n",
    "df_all = df_all_onehot\n",
    "del df_all_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define indices for train, val, design and test.  You should get the same numbers in each as in the comments below.  If you do not, then something has gone wrong and you should ask on Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define index for train, val, design, test\n",
    "idx_train  = np.where(df_all['fold'].isin(np.arange(0,6)))[0]\n",
    "idx_val    = np.where(df_all['fold'].isin([6,7]))[0]\n",
    "idx_design = np.where(df_all['fold'].isin(np.arange(0,8)))[0]\n",
    "idx_test   = np.where(df_all['fold'].isin([8,9]))[0]\n",
    "\n",
    "print(len(idx_train))  # 1,749\n",
    "print(len(idx_val))    #   586\n",
    "print(len(idx_design)) # 2,335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardise**\n",
    "\n",
    "As per our discussion on Moodle, we are giving each of our features a mean of 0 and standard deviation of 1.  This is the same as \"standard\" normal distribution, hence (presumably?) the name standardise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_ind_numeric:\n",
    "    x = df_all[var].values\n",
    "    x -= np.mean(x, axis=0)\n",
    "    x /= np.sqrt(np.mean(x ** 2, axis=0))\n",
    "    df_all[var] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare basis functions**\n",
    "\n",
    "I encourage you to experiment below with the variables that are splined (currently set to minimum cardinality > 8) and the percentiles used (currently set to [10, 20, 40, 60, 80, 90]).  However if you are short of time, the settings below should give a reasonable answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind_tospline = df_all[vars_ind_numeric].columns[(df_all[vars_ind_numeric].nunique() > 8)].tolist()\n",
    "\n",
    "def fn_tosplines(x):\n",
    "    x = x.values\n",
    "    # hack: remove zeros to avoid issues where lots of values are zero\n",
    "    x_nonzero = x[x != 0]\n",
    "    ptiles = np.percentile(x_nonzero, [10, 20, 40, 60, 80, 90])\n",
    "    #print(var, ptiles)\n",
    "    df_ptiles = pd.DataFrame({var: x})\n",
    "    for idx, ptile in enumerate(ptiles):\n",
    "        df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "    return(df_ptiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_ind_tospline:\n",
    "    df_ptiles = fn_tosplines(df_all[var])\n",
    "    df_all.drop(columns=[var], inplace=True)\n",
    "    vars_ind_numeric.remove(var)\n",
    "    df_all = pd.concat([df_all, df_ptiles], axis=1, sort=False)\n",
    "    vars_ind_numeric.extend(df_ptiles.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_ind = vars_ind_onehot + vars_ind_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all[vars_ind].values\n",
    "y = df_all[var_dep].values\n",
    "\n",
    "X_train  = X[idx_train, :]\n",
    "X_val    = X[idx_val, :]\n",
    "X_design = X[idx_design, :]\n",
    "X_test   = X[idx_test, :]\n",
    "\n",
    "y_train  = df_all[var_dep].iloc[idx_train].copy().values.ravel()\n",
    "y_val    = df_all[var_dep].iloc[idx_val].copy().values.ravel()\n",
    "y_design = df_all[var_dep].iloc[idx_design].copy().values.ravel()\n",
    "y_test   = df_all[var_dep].iloc[idx_test].copy().values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net with CV\n",
    "\n",
    "Below I have set up the code to test one given value of l1_ratio.  You should type in a value, run through the code, experiment a little with lambda and see the performance.  You should then do the same for difference values of l1_ratio.  The values I tested for l1_ratio are [0, 0.25, 0.5, 0.75, 0.9, 0.99]\n",
    "\n",
    "I did not change the list for \"alphas\" in any of my tests.  This is not idea.  But I find that sklearn ElasticNet implementations tend to fail to converge when it does not \"like\" what you put in - since these worked and gave a semi-decent answer, I left it like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate and fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# below, alpha is regularisation strength\n",
    "# note impact of selection='random' vs cyclical on time taken\n",
    "#del enCV_\n",
    "\n",
    "enCV_ = ElasticNetCV(\n",
    "                     # type in whatever value you are testing here\n",
    "                     l1_ratio=#type value here\n",
    "    \n",
    "                     ,alphas=[2**num for num in range(-6,5)]\n",
    "                     # if you get non-convergence, you many need to increase max_iter\n",
    "                     ,max_iter=5000 \n",
    "                     # we already normalised but you may get a better answer if \n",
    "                     # you turn this on.  You should get a different answer at least\n",
    "                     # since we did not normalise the splines (as discussed on Moodle)\n",
    "                     ,normalize=False\n",
    "                     ,cv=10\n",
    "                     ,random_state=2018\n",
    "                     ,selection='random'\n",
    "                     )\n",
    "\n",
    "enCV_.fit(X=X_design, y=y_design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame({'variable': vars_ind, 'coefficient': enCV_.coef_})\n",
    "df_coef = df_coef[df_coef['coefficient'] != 0]\n",
    "print(\"Total number of coefficients: \", df_coef.shape[0])\n",
    "df_coef['sign'] = np.where(df_coef['coefficient'].values < 0, 'NEG', 'POS')\n",
    "df_coef['coefficient_abs'] = np.abs(df_coef['coefficient'])\n",
    "print(\"Total number of non-zero coefficients: \", df_coef.shape[0])\n",
    "\n",
    "print(\"Largest coefficients...\")\n",
    "df_coef.sort_values('coefficient_abs', ascending=False, inplace=True)\n",
    "df_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularisation strength**\n",
    "\n",
    "Find the regularisation stregnth chosen by sklearns CV.  Please remember that the correct name for regularisation stregnth is lambda.  sklearn calls it alpha just to avoid confusion with the lambda keyword in Python.  When we move next week to H2O, you will see it called lambda_ (with an underscore)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did sklearn choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enCV_.alpha_)\n",
    "print(np.log10(enCV_.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now graph the validation curves, if val performance is very flat near the value that sklearn chose, this may indicate that we can increase the value, get a simpler model with less overfitting but still do OK on test.\n",
    "\n",
    "Note that these validation curves are based on MSE instead of MAE, I used that too.  This is not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_log_lambdas = -np.log10(enCV_.alphas_)\n",
    "\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.plot(m_log_lambdas, enCV_.mse_path_, ':')\n",
    "ax1.plot(m_log_lambdas, enCV_.mse_path_.mean(axis=-1),\n",
    "         'k',\n",
    "         label='Average across the folds',\n",
    "         linewidth=2)\n",
    "\n",
    "ax1.axvline(-np.log10(enCV_.alpha_),\n",
    "            linestyle='--', \n",
    "            color='k',\n",
    "            label='alpha: CV estimate')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_xlabel('-log10(lambda)')\n",
    "ax1.set_ylabel('Mean square error')\n",
    "ax1.set_title('Mean square error on each fold')\n",
    "_ = ax1.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the best regularisation stregth chosen by sklearn and also one or two higher ones for you to test if you think you might improve your model...\n",
    "\n",
    "Be careful when reading off the x-axis it is MINUS log10 of alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance over test**\n",
    "\n",
    "We will try out some different choices on train-val data.\n",
    "\n",
    "In real life you cannot fit models on test data. Also in Kaggle competitions you cannot do this.  Test data they give you (which is called the public leadboard data) is not all of the test data, so if you overfit to it, you will do very poorly in the final scoring over the rest of the test data (which is called the private leaderboard). \n",
    "\n",
    "However, when finding the best solution, I did \"cheat\" by looking a few times at models on all of design data and seeing performance on test.  The code below is more correct, but at least for this assignment when you get to checking performance on test, you should try a few of your best models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, type in whatever l1_ratio you are testing and then some values for alpha.  See which does best and write it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ = ElasticNet(alpha=#type value here\n",
    "                 ,l1_ratio=#type value here\n",
    "                 ,normalize=False\n",
    "                 ,random_state=2018\n",
    "                 ,selection='random'\n",
    "                 ,max_iter=5000\n",
    "                 )\n",
    "\n",
    "en_.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train  = enCV_.predict(X_train)\n",
    "pred_val    = enCV_.predict(X_val)\n",
    "#pred_test   = enCV_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: train:\", fn_MAE(y_train, pred_train))\n",
    "print(\"MAE: val:\", fn_MAE(y_val, pred_val))\n",
    "print(fn_MAE(y_val,   pred_val) - fn_MAE(y_train, pred_train))\n",
    "#print(\"MAE: design:\", fn_MAE(y_design, pred_design))\n",
    "#print(\"MAE: test:\",   fn_MAE(y_test,   pred_test))\n",
    "#print(fn_MAE(y_test,   pred_test) - fn_MAE(y_design, pred_design))\n",
    "# standardise everything after splines created gave similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above process for a few different values of regularisation strength and l1_ratio. There is notthing to stop you trying a few different values here.  Though as discussed above it is bad practice in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ = ElasticNet(alpha=#your choice here\n",
    "                 ,l1_ratio=#your choice here\n",
    "                 ,normalize=False\n",
    "                 ,random_state=2018\n",
    "                 ,selection='random'\n",
    "                 ,max_iter=5000\n",
    "                 )\n",
    "\n",
    "en_.fit(X=X_design, y=y_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_design = en_.predict(X_design)\n",
    "pred_test   = en_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fn_MAE(y_design, pred_design))\n",
    "print(fn_MAE(y_test,   pred_test))\n",
    "print(fn_MAE(y_test,   pred_test) - fn_MAE(y_design, pred_design))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function\n",
    "\n",
    "Once you have something you are comfortable with, copy all of the code you used to create the models into the function below (making sure it is correctly indented.  To avoid you having to edit the code, we keep the name of the data passed to the function as df_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_ames_en(df_all):\n",
    "    \n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    \n",
    "    from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def convert(name):\n",
    "        s1 = re.sub('\\.', '_', name)\n",
    "        return s1.lower()\n",
    "\n",
    "    def fn_MAE(actuals, predictions):\n",
    "        return np.round(np.mean(np.abs(predictions - actuals)), 0)\n",
    "\n",
    "    def fn_tosplines(x):\n",
    "        x = x.values\n",
    "        # hack: remove zeros to avoid issues where lots of values are zero\n",
    "        x_nonzero = x[x != 0]\n",
    "        ptiles = np.percentile(x_nonzero, [10, 20, 40, 60, 80, 90])\n",
    "        #print(var, ptiles)\n",
    "        df_ptiles = pd.DataFrame({var: x})\n",
    "        for idx, ptile in enumerate(ptiles):\n",
    "            df_ptiles[var + '_' + str(idx)] = np.maximum(0, x - ptiles[idx])\n",
    "        return(df_ptiles)\n",
    "\n",
    "    \n",
    "    # change column names to closer to camel case\n",
    "    colnames = df_all.columns.values\n",
    "    colnames = list(map(convert, colnames))\n",
    "    df_all.columns = colnames\n",
    "    del convert, colnames\n",
    "    \n",
    "    # define variables\n",
    "    vars_all = df_all.columns.values\n",
    "    var_dep = ['saleprice']\n",
    "    \n",
    "    vars_notToUse = ['order', 'pid']\n",
    "    vars_ind = [var for var in vars_all if var not in (vars_notToUse + var_dep)]\n",
    "    vars_ind_numeric = list(df_all[vars_ind].columns[df_all[vars_ind].dtypes != 'object'])\n",
    "    \n",
    "    # Deal with missings as per 02a\n",
    "    vars_toDrop = ['lot_frontage', 'garage_yr_blt', 'mas_vnr_area']\n",
    "    df_all.drop(labels=vars_toDrop,\n",
    "                axis=1,\n",
    "                inplace=True)\n",
    "    \n",
    "    vars_ind = [var for var in vars_ind if var not in vars_toDrop]\n",
    "    vars_ind_numeric = [var for var in vars_ind_numeric if var not in vars_toDrop]\n",
    "    df_all.dropna(inplace = True)\n",
    "    \n",
    "    # remove outliers\n",
    "    df_all = df_all[df_all['gr_liv_area'] <= 4000]\n",
    "    df_all.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # create onehot columns\n",
    "    vars_ind_categorical = df_all.columns[df_all.dtypes == 'object'].tolist()\n",
    "    vars_ind_onehot = []\n",
    "    \n",
    "    df_all_onehot = df_all.copy()\n",
    "    \n",
    "    for col in vars_ind_categorical:   \n",
    "        # use pd.get_dummies on  df_all[col]\n",
    "        df_oh = pd.get_dummies(df_all[col], drop_first=False) \n",
    "        # Find the name of the most frequent column\n",
    "        col_mostFreq = df_oh.sum(axis = 0).idxmax()\n",
    "        # Drop the column of the most frequent category (using df_oh.drop)\n",
    "        df_oh = df_oh.drop(col_mostFreq, axis=1)\n",
    "        # Rename the columns to have the original variable name as a prefix\n",
    "        oh_names = col + '_' + df_oh.columns\n",
    "        df_oh.columns = oh_names\n",
    "        df_all_onehot = pd.concat([df_all_onehot, df_oh], axis = 1, sort = False)\n",
    "        del df_all_onehot[col]\n",
    "        vars_ind_onehot.extend(oh_names)\n",
    "        \n",
    "    # create fold\n",
    "    rng = np.random.RandomState(2018)\n",
    "    fold = rng.randint(0, 10, df_all.shape[0])\n",
    "    df_all_onehot['fold'] = fold\n",
    "        \n",
    "    # rename df_all_onehot to df_all as this is now the data we will be using for\n",
    "    # the rest of this work\n",
    "    df_all = df_all_onehot\n",
    "    del df_all_onehot\n",
    "        \n",
    "    # define index for train, val, design, test\n",
    "    idx_train  = np.where(df_all['fold'].isin(np.arange(0,6)))[0]\n",
    "    idx_val    = np.where(df_all['fold'].isin([6,7]))[0]\n",
    "    idx_design = np.where(df_all['fold'].isin(np.arange(0,8)))[0]\n",
    "    idx_test   = np.where(df_all['fold'].isin([8,9]))[0]\n",
    "   \n",
    "    # standardise features\n",
    "    for var in vars_ind_numeric:\n",
    "        x = df_all[var].values\n",
    "        x -= np.mean(x, axis=0)\n",
    "        x /= np.sqrt(np.mean(x ** 2, axis=0))\n",
    "        df_all[var] = x\n",
    "            \n",
    "    vars_ind_tospline = df_all[vars_ind_numeric].columns[(df_all[vars_ind_numeric].nunique() > 8)].tolist()\n",
    "            \n",
    "    for var in vars_ind_tospline:\n",
    "        df_ptiles = fn_tosplines(df_all[var])\n",
    "        df_all.drop(columns=[var], inplace=True)\n",
    "        vars_ind_numeric.remove(var)\n",
    "        df_all = pd.concat([df_all, df_ptiles], axis=1, sort=False)\n",
    "        vars_ind_numeric.extend(df_ptiles.columns.tolist())\n",
    "                \n",
    "    vars_ind = vars_ind_onehot + vars_ind_numeric\n",
    "                \n",
    "    X = df_all[vars_ind].values\n",
    "    y = df_all[var_dep].values\n",
    "                \n",
    "    X_design = X[idx_design, :]\n",
    "    X_test   = X[idx_test, :]\n",
    "    y_design = df_all[var_dep].iloc[idx_design].copy().values.ravel()\n",
    "    y_test   = df_all[var_dep].iloc[idx_test].copy().values.ravel()\n",
    "                \n",
    "    X = df_all[vars_ind].values\n",
    "    y = df_all[var_dep].values\n",
    "                \n",
    "    X_train  = X[idx_train, :]\n",
    "    X_val    = X[idx_val, :]\n",
    "    X_design = X[idx_design, :]\n",
    "    X_test   = X[idx_test, :]\n",
    "                \n",
    "    y_train  = df_all[var_dep].iloc[idx_train].copy().values.ravel()\n",
    "    y_val    = df_all[var_dep].iloc[idx_val].copy().values.ravel()\n",
    "    y_design = df_all[var_dep].iloc[idx_design].copy().values.ravel()\n",
    "    y_test   = df_all[var_dep].iloc[idx_test].copy().values.ravel()\n",
    "                \n",
    "    # Copy enough of your ElasticNetCV code here so that I can see one of your experiments\n",
    "    # and get an idea of the method you used to tune the hyper parameters\n",
    "\n",
    "        \n",
    "    # Now copy the code for your final model here\n",
    "    en_ = ElasticNet()\n",
    "    \n",
    "    en_ = en_.fit()\n",
    "\n",
    "    pred_design  =\n",
    "    pred_test    =\n",
    "                \n",
    "    # calculate MAE on test and non test but then hard code in the return statement\n",
    "    mae_design =\n",
    "    mae_test =\n",
    "                \n",
    "    return en_, X, y, hard code your mae_design here eg 14123, also mae_test eg 13321\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created your function, copy it to a plain text .py file and save it in your PCode directory. Now if you have time, test it with the test notebook provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
